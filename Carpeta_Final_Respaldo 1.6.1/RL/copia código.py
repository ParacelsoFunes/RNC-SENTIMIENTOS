#Matriz de recompensas se utiliza aprendisaje por refuerzo (prueba y error) respuesta correcta se asigna una recompensa aprende de su experiencia
#Componentes: 

# -1 en caso de penalización (el agente no se mueve camino incorrecto)
# 0 en caso que el agente se pueda mover (se cambia el estado del agente)
# 100 en caso de llegar a la meta, deja me moverse el agente
#La meta sería que no abandone y los estados por donde debe transitar para no abandonar
# las filas van a representar los estados y las columnas representan las acciones a realizar por el agente. es decir la maquina.
# Agente(la maquina) 
# El entorno(con quien va a interactuar el agente es decir la situación)
# los estados(el camino que sirve para rastrear posición del agente)
# Acciones son los movimiento que realiza el agente a travez de los estados esta es la parte del refuerzo
# Recompensas (se establecen las recompensas en caso de acertar y las penalizaciones en caso de no acertar) aqui va la matriz.
#Matriz de recompensas con 34 estados, las filas representan las acciones que el agente tiene que hacer para llegar a la meta.
# Las filas son las acciones.
# Se tiene que construir la matriz conforme a la base de datos. 

from math import gamma
import numpy as np
import random


#Matriz de recompensas.

'''recompensas = np.array([
[-1, 0, -1, -1, -1, 100],
[0,-1, -1, 0, -1, -1],
[-1, -1, -1, -1, -1],
[-1, 0, -1, -1, -1, -1],
[-1, -1, -1, -1, -1, 1],
[0, -1, -1, -1, -1, 100]
])'''

#El resultado final del arreglo es encontrar que el agente elija las acciones que le den mayor recompensa positiva
#  y evitar las negativas paso 1.

# para hacer la construcción de matrices se puede utilizar rpa (automatización robotizada)
recompensas_tamano_efecto = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
'''recompensas2 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas3 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1,],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas4 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas5 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas6 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas7 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas8 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[100,-1,-1,-1,-1],[-1,-1,0,-1,100],[-1,-1,0,-1,-1]])
recompensas9 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas10 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas11 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas12 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,-1,0,-1,-1],[-1,-1,0,-1,-1]])
recompensas13 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas14 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[100,-1,-1,-1,-1],[-1,-1,-1,-1,100],[-1,-1,0,-1,-1]])
recompensas15 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1,],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas16 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas17 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas18 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas19 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100][-1,-1,-1,-1,-1]])
recompensas20 = np.array([[-1,0,-1,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[100,-1,-1,-1,-1],[-1,-1,0,-1,100],[-1,-1,0,-1,-1]])
recompensas21 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas22 = np.array([[-1,0,-1,0,-1,],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas23 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas24 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas25 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas26 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas27 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,3,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,1,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas28 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas29 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas30 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,-1,-1,-1]])
recompensas31 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas32 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas33 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas34 = np.array([[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,-1,100,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[100,-1,-1,-1,-1],[-1,-1,0,-1,100],[-1,-1,0,-1,-1]])
recompensas35 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas36 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100],[-1,-1,0,-1,-1]])
recompensas37 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas38 = np.array([[-1,0,-1,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,0,-1],[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])# revisar el tercer valor desde la matriz uno hasta aqui.
recompensas39 = np.array([[-1,0,-1,0],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas40 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas41 = np.array([[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,-1,0,-1,-1]])
recompensas42 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas43 = np.array([[-1,0,-1,0,-1,],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas44 = np.array([[-1,0,-1,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,0,-1],[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,-1,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[100,-1,-1,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas45 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1,],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas46 = np.array([[-1,0,-1,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,-1,-1,-1]])
recompensas47 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,-1,-1,-1]])
recompensas48 = np.array([[-1,0,-1,0-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1,],[-1,0,0,-1,100]]),[-1,-1,0,-1,-1]
recompensas49 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,-1,-1],[-1,-1,0,-1,-1],[-1,-1,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[-1,-1,0,-1,-1],[-1,-1,-1,0,-1],[-1,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100],[-1,-1,0,-1,-1]])
recompensas50 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas51 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas52 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
recompensas53 = np.array([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100],[-1,-1,0,-1,-1]])
#matriz_recompensas_agrupadas = [recompensas,recompensas2,recompensas3,recompensas4,recompensas5,recompensas6,recompensas7,recompensas8,recompensas9,recompensas10,recompensas11,recompensas12,recompensas13,recompensas14,recompensas15,recompensas16,recompensas17,recompensas18,recompensas19,recompensas20,recompensas21,recompensas22,recompensas23,recompensas24,recompensas25,recompensas26,recompensas27,recompensas28,recompensas29,recompensas30,recompensas31,recompensas32,recompensas33,recompensas34,recompensas36,recompensas37,recompensas38,recompensas39,recompensas40,recompensas41,recompensas42,recompensas43,recompensas44,recompensas45,recompensas46,recompensas47,recompensas48,recompensas49,recompensas50,recompensas51,recompensas52,recompensas53]
'''
Recompensa_resto_de_investigacion = np.array([[-1,0,-1,0,-1],[-1,0,0,0-1],[-1,0,0,0,-1],[-1,0,0,0-1],[ -1,0,0,0-1],[ -1,0,0,0-1],[ -1,0,0,0-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa2 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0-1],[-1,0,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa3 = np.array ([[-1,-1,-1,0-1],[-1,-1,0,0-1],[ -1,-1,0,0-1],[-1,0,0,-1,-1],[ -1,0,0,-1,-1],[-1,-1,-1,-1,-1],[-1,0,-1,-1,-1],[-1,-1,-1,100,-1],[ 0,-1,-1,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[ 0,-1,-1,0,-1],[-1,-1,0,-1,-1],[-1,-1,-1,0,-1],[-1,-1,-1,-1,-1],[-1,-1,0,-1,-1],[100,-1,-1,-1,-1],[-1,-1,-1,-1,100]])
Recompensa4 = np.array ([[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,0,0,-1,-1],[-1,-1,0,0,-1],[-1,-1,-1,0-1],[-1,0,0,0,-1],[-1,0,0,0-1],[-1,0,0,100,-1],[0,-1,-1,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,-1,-1],[-1,-1,0,-1,-1],[0,-1,-1,0,-1],[ 0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa5 = np.array ([[-1,0,-1,-1,-1],[-1,0,0,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[ 0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa6 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa7 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa8 = np. array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa9 = np.array ([[-1,0,-1,0,-1],[ -1,0,-1,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa10 = np.array ([[-1,-1,-1,-1,-1],[-1,-1,-1,0,-1],[ -1,-1,-1,0,-1],[-1,0,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,100,-1],[-1,-1,-1,-1,-1],[ -1,-1,-1,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa11 = np.array ([[-1,0,-1,-1,-1],[-1,0,-1,0-1],[-1,-1,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa12 = np.array ([[-1,0,-1,-1,-1],[-1,0,-1,0-1],[-1,-1,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa13 = np.array ([[-1,0,-1,-1,-1],[-1,0,-1,0-1],[-1,-1,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa14 = np.array ([[-1,0,-1,-1,-1],[-1,0,-1,0-1],[-1,-1,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa15 = np.array ([[-1,0,-1,-1,-1],[-1,0,-1,0-1],[-1,-1,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa16 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa17 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,-1,-1],[ -1,-1,0,-1,-1],[-1,0,-1,-1,-1],[-1,0,0,0,-1],[-1,0,-1,100,-1],[0,-1,-1,0,-1],[0,-1,0,-1,-1],[ 0,-1,0,-1,-1],[0,-1,-1,-1,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[-1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa18 = np.array ([[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,-1,-1],[0,-1,-1,0,-1],[ 0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa19 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,-1,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[ 0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa20 = np.array ([[-1,0,-1,-1,-1],[-1,0,0,0,-1],[-1,0,-1,-1,-1],[-1,0,0,0,-1],[-1,0,-1,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[-1,-1,0,0,-1],[0,-1,0,0,-1],[-1,-1,0,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa21 = np.array ([[-1,-1,-1,-1,-1],[-1,-1,-1,0,-1],[ -1,-1,-1,0,-1],[-1,0,0,-1,-1],[ -1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,-1,-1,100,-1],[-1,-1,-1,-1,-1],[ -1,-1,-1,-1,-1],[0,-1,-1,0,-1],[ 0,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[-1,-1,0,-1,-1],[ -1,-1,0,-1,-1],[100,-1,-1,-1,-1],[-1,-1,-1,-1,100]])
Recompensa22 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,-1,-1],[ -1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[0,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa23 = np.array ([[-1,0,-1,-1,-1],[-1,0,0,0,-1],[-1,-1,-1,0,-1],[-1,0,0,-1,-1],[ -1,0,0,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[ -1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa24 = np.array ([[-1,0,-1,0,-1],[-1,0,-1,-1,-1],[-1,0,0,0,-1],[-1,0,-1,-1,1],[-1,0,0,-1,-1],[-1,-1,-1,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,100,-1],[-1,-1,-1,-0,-1],[0,-1,0,0,-1],[-1,-1,0,0,-1],[0,-1,0,0,-1],[-1,-1,0,-1,-1],[-1,-1,0,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa25 = np.array ([[-1,0,-1,-1,-1],[-1,0,-1,0,-1],[ -1,0,-1,0,-1],[-1,-1,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,-1,-1,-1],[0,-1,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[-1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa26 = np.array ([[-1,0,-1,-1,-1],[-1,0,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,-1,-1],[0,-1,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[ -1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa27 = np.array ([[-1,0,-1,-1,-1],[-1,0,0,0,-1],[-1,0,-1,0,-1],[-1,-1,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,0,-1],[-1,-1,0,0,-1],[0,-1,0,-1,-1	],[0,-1,0,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa28 = np.array ([[-1,0,-1,-1,-1],[-1,-1,-1,0,-1],[-1,0,-1,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,-1,-1],[-1,-1,-1,0,-1],[0,-1,-1,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa29 = np.array ([[-1,-1,-1,-1,-1],[-1,-1,-1,0,-1],[-1,0,-1,-1,-1],[-1,-1,0,0,-1],[-1,0,-1,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,100,-1],[ -1,-1,-1,-1,-1],[ -1,-1,-1,0,-1],[ 0,-1,-1,-1,-1],[ -1,-1,0,0,-1],[ 0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa30 = np.array ([[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[-1,-1,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,-1,-1],[ 0,-1,-1,-1,-1],[ 0,-1,-1,-1,-1],[0,-1,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[ -1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa31 = np.array ([[-1,0,-1,-1,-1],[-1,0,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[0,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa32 = np.array ([[-1,-1,-1,-1,-1],[-1,-1,0,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,-1,-1],[-1,-1,-1,-1,-1],[ 0,-1,-1,-1,-1],[0,-1,-1,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa33 = np.array ([[-1,-1,-1,-1,-1],[-1,-1,0,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,-1,-1],[-1,-1,-1,-1,-1],[ 0,-1,-1,-1,-1],[0,-1,-1,0,-1],[ 0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa34 = np.array ([[-1,0,-1,-1,-1],[-1,0,0,0,-1],[-1,-1,-1,0,-1],[-1,0,0,-1,-1],[ -1,0,0,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,0,-1],[-1,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[ -1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa35 = np.array ([[-1,-1,-1,0,-1],[ -1,-1,-1,0,-1],[-1,0,0,0,-1],[-1,0,0,-1,-1],[ -1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,-1,-1,100,-1],[-1,-1,-1,-1,-1],[0,-1,-1,0,-1],[ 0,-1,-1,0,-1],[0,-1,0,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[-1,-1,0,-1,-1],[ -1,-1,0,-1,-1],[100,-1,-1,-1,-1],[-1,-1,-1,-1,100]])
Recompensa36 = np.array ([[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,0,-1],[-1,-1,-1,-1,-1],[ -1,-1,-1,-1,-1],[ -1,-1,-1,-1,-1],[ -1,-1,-1,-1,-1],[-1,0,-1,100,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[-1,-1,0,-1,-1],[-1,-1,-1,0,-1],[ -1,-1,-1,-1,-1],[ -1,-1,-1,-1,-1],[ -1,-1,-1,0,-1],[-1,-1,-1,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa37 = np.array ([[-1,0,-1,0,-1],[ -1,0,-1,0,-1],[-1,0,0,-1,-1],[ -1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,100,-1],[ -1,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[ -1,-1,0,0,-1],[ -1,-1,0,0,-1],[ -1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa38 = np.array ([[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,0,0,-1,-1],[-1,-1,0,-1,-1],[-1,0,0,-1,-1],[-1,0,-1,-1,-1],[ -1,0,-1,-1,-1],[-1,0,-1,100,-1],[0,-1,-1,-1,-1],[0,-1,-1,0,-1],[0,-1,-1,-1,-1],[0,-1,0,0,-1],[-1,-1,-1,0,-1],[-1,-1,0,0,-1],[ -1,-1,0,0,-1],[ -1,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,-1,-1,100]])
Recompensa39 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,0,-1],[ -1,0,0,0,-1],[-1,0,0,100,-1],[0,-1,-1,0,-1],[0,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[ 0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
Recompensa40 = np.array ([[-1,0,-1,0,-1],[-1,0,0,0,-1],[-1,-1,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[-1,0,0,0,-1],[1,0,0,100,-1],[ 0,-1,-1,0,-1],[0,-1,0,-1,-1],[0,-1,0,0,-1],[0,-1,-1,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[0,-1,0,0,-1],[100,-1,0,-1,-1],[-1,0,0,-1,100]])
matriz_Recompensa_agrupadas_dos = [Recompensa_resto_de_investigacion,Recompensa2,Recompensa3,Recompensa4,Recompensa5,Recompensa6,Recompensa7,Recompensa8,Recompensa9,Recompensa10,Recompensa11,Recompensa12,Recompensa13,Recompensa14,Recompensa15,Recompensa16,Recompensa17,Recompensa18,Recompensa19,Recompensa20,Recompensa21,Recompensa22,Recompensa23,Recompensa24,Recompensa25,Recompensa26,Recompensa27,Recompensa28,Recompensa29,Recompensa30,Recompensa31,Recompensa32,Recompensa33,Recompensa34,Recompensa35,Recompensa36,Recompensa37,Recompensa38,Recompensa39,Recompensa40]


#for i in matriz_recompensas_agrupadas: 
 #   print("matriz recompensas agrupadas:" ,matriz_recompensas_agrupadas)
def estado_de_inicio():
    return np.random.randint(0,15) #nos esta dando un número aleatorio para saber en donde empezar #Una vez terminada de agregar a cada recompensa poner número total de casos (Estados) en recompensas

def estado_de_inicio_resto_de_investigacion():
    return np.random.randint(0,17)
    
def obtener_acciones(estado_actual, matriz_recompensas):
    acciones_disponibles =[]
    print("matriz de recompensas", matriz_recompensas)
    
    for accion in enumerate(matriz_recompensas[estado_actual]): #No se puso arriba porque si se pone quedaría fuera del for y no recorreria todas las acciones.
        if accion[1] != -1:
            acciones_disponibles.append(accion[0])

    escoger_accion = random.choice(acciones_disponibles)
    print(" Estado actual: ", estado_actual)
    print(" Eleccion aleatoria de la acción en: ", acciones_disponibles, "es: ",escoger_accion)
    return escoger_accion

def obtener_acciones_resto_de_investigacion(estado_actual_resto_de_investigacion,matriz_Recompensas_resto_de_investigacion):
    acciones_disponibles =[]
    for accion in enumerate(matriz_Recompensas_resto_de_investigacion,estado_actual_resto_de_investigacion):
        if accion [1] != -1:
            acciones_disponibles.append(accion[0])
    escoger_accion =random.choice(acciones_disponibles)
    print("Estado actual: " ,estado_actual)
    print("Eleccion aleatoria de la acción en: ", acciones_disponibles, " es ", escoger_accion)

# es el ciclo para contar y determinar ruta más corta de cada una de las matrices.
estado_actual = 13 #AUTOMATIZAR PARA RECORRER TODOS LOS ESTADOS
estado_actual_resto_de_investigacion = 17


accion = obtener_acciones(estado_actual,recompensas_tamano_efecto)
print(accion)
accion_resto_de_investigacion = obtener_acciones_resto_de_investigacion(estado_actual_resto_de_investigacion,Recompensa_resto_de_investigacion)
print(accion_resto_de_investigacion)

'''for contador_de_matrices in matriz_recompensas_agrupadas:
    accion = obtener_acciones(estado_actual,contador_de_matrices)
    print("*********************")
    print("accion:",contador_de_matrices)
    print(accion)'''

# paso 2 el agente aprenda la acción realizada y decida la acción en consecuencia. Se va utilizar el metodo de q learning 
# Matrix de calidad permite determinan que tan util es la acción para generar una recompensa.

#*************FASE DOS************
#se utiliza q learning algoritmo de aprendizaje por refuerzo. teniendo el estado actual ayuda a encontrar la mejor acción que debe tomar el agente.
#q en de calidad, la calidad representa que tan util es la acción para obtener una recompensa.
# Funciona igual que la matriz de recompensas en donde las filas son los estados y las columnas son las acciones. Todos los elementos de la matriz inicialmente de la matiz son 0
#la forma en que los valores de los elementos cambia según las recompensas otorgadas por cada acción.
#Exiten dos formas de  que el agente interactuar con el entorna la primera es la exploración esta es de manera aleatoria.
#la segunda la explotación en esta se usa la matriz q como referencia y se ven todas las acciones posibles para ese estado. 
#El agente selecciona la acción que le permite maximizar la recompensa dentro de un conjunto de acciones. para que funcionen los dos metodos se apoya en la ecuación de bellman
#La ecuación observa la matriz q y la recompensa actual y con la info que tiene ayuda a decidir la acción que va a tomar el agente para maximizar la recompensa

#ECUACIÓN DE BELLMAN: próxima recompensa (estado, acción) = recompensa actual (estado,acción) + gama + matriz q[maximo(proxima acción, todas las acciones)]
# la , se para indicar que va a recibir un parametro #Q^(s,a)=Q(s,a)+α[R+(γ maxQ(s',))-Q(s,a)]
#En donde (s,a) es valora actual.
#α es igual a taza de aprendizaje y regula la velocidad en que aprende.
#R es recompensa.
#γ es taza de descuento tiene en cuenta la recompensa a corto y largo plazo. el valora varia entre 0.8 y 0.99
#maxQ(s',) es el valor optimo esperado.
#-Q(s,a) es valor actual.

#Matriz de calidad1
#Esto se construye para uno solo caso.
'''print(" *******************************************: ")
print(" INICIA MATRIZ Q: ")
print(" *******************************************: ")
#matriz_calidad = np.zeros([5,14])
matriz_calidad = np.zeros([14,5])# Una vez terminado de agregar los caso nuevo se pone el número total de casos(Estados).
print(matriz_calidad)
gamma = 0.8 
def tomar_accion(estado_actual, matriz_recompensas, gamma):
    accion = obtener_acciones(estado_actual, matriz_recompensas)
    recompensa_actual = matriz_recompensas[estado_actual, accion]
    print('*****************')
    print('recompensa actual: ',recompensa_actual)
    #print(matriz_calidad)
    recompensa_nueva = max(matriz_calidad[accion,])
    print('recompensa nueva: ',recompensa_nueva)
    estado_actualq = recompensa_actual+(gamma * recompensa_nueva)
    print('Estado actual Q: ',estado_actualq)
    
    print(" *******************************************: ")
    print(" ACTUALIZACIÓN DE MATRIZ Q: ")
    print(" *******************************************: ")
    matriz_calidad[estado_actual,accion] = estado_actualq
    print('Matriz de calidad',"\n",matriz_calidad) 
    nuevo_estado = accion
    if nuevo_estado == 13:
        print('Objetivo alcanzado!!!!')
    else:
         print(f'Estado anterior: {estado_actual} Nuevo estado: {nuevo_estado}')
    return nuevo_estado
tomar_accion(estado_actual,recompensas,gamma)'''